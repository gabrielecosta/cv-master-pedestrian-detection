{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primo approccio per estrarre gli HOG di una immagine usando OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413, 550, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Images/000040.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applico un resize all'immagine in maniera tale che sia piccolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/gabriele/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# image = cv2.resize(image, None, fx=0.3, fy=0.3)\n",
    "# image = cv2.resize(image, width=min(400, image.shape[1]))\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'HOGDescriptor'\n> Overload resolution failed:\n>  - HOGDescriptor() missing required argument '_blockSize' (pos 2)\n>  - Can't convert object to 'str' for 'filename'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m winSize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# blockSize = (16,16)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# blockStride = (8,8)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# cellSize = (8,8)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# gammaCorrection = 0\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# nlevels = 64\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m hog \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHOGDescriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinSize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m hog\u001b[38;5;241m.\u001b[39msetSVMDetector(cv2\u001b[38;5;241m.\u001b[39mHOGDescriptor_getDefaultPeopleDetector())\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'HOGDescriptor'\n> Overload resolution failed:\n>  - HOGDescriptor() missing required argument '_blockSize' (pos 2)\n>  - Can't convert object to 'str' for 'filename'\n"
     ]
    }
   ],
   "source": [
    "# inizializzo il HOG person detector\n",
    "winSize = (64,128)\n",
    "# blockSize = (16,16)\n",
    "# blockStride = (8,8)\n",
    "# cellSize = (8,8)\n",
    "# nbins = 9\n",
    "# derivAperture = 1\n",
    "# winSigma = 4.\n",
    "# histogramNormType = 0\n",
    "# L2HysThreshold = 2.0000000000000001e-01\n",
    "# gammaCorrection = 0\n",
    "# nlevels = 64\n",
    "hog = cv2.HOGDescriptor(winSize)\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@dnemutlu/hog-feature-descriptor-263313c3b40d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ora faccio detecting delle persone\n",
    "# Detect people in the image\n",
    "locations, confidence = hog.detectMultiScale(image, padding=(4,4), scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(locations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[925, 373,  80, 160],\n",
       "       [167, 359, 115, 230],\n",
       "       [635, 338, 134, 267],\n",
       "       [290, 360, 122, 243]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.11320335, 2.06735   , 0.59617003, 0.90654029])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x,y,w,h) in locations:\n",
    "    cv2.rectangle(new_image, (x,y), (x+w, y+h), (0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image', new_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso per ogni area trovata estraggo una sottoimmagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 80, 3)\n",
      "(230, 115, 3)\n",
      "(267, 134, 3)\n",
      "(243, 122, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (x,y,w,h) in locations:\n",
    "    sub_image = image[y:y+h, x:x+w].copy()\n",
    "    print(sub_image.shape)\n",
    "    pedestrians.append(sub_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pedestrians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pedestrian in pedestrians:\n",
    "    cv2.imshow('Pedone', pedestrian)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedone1, pedone2, pedone3, pedone4 = pedestrians\n",
    "\n",
    "cv2.imshow('Pedone1', pedone1)\n",
    "cv2.imshow('Pedone2', pedone2)\n",
    "cv2.imshow('Pedone3', pedone3)\n",
    "cv2.imshow('Pedone4', pedone4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedoni = [pedone1, pedone2, pedone3, pedone4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ogni pedone applico prima un resize e poi filtro gaussiano:\n",
    "(w,h) = (128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 64, 3)\n",
      "(128, 64, 3)\n",
      "(128, 64, 3)\n",
      "(128, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# res = cv2.resize(img, dsize=(54, 140), interpolation=cv2.INTER_CUBIC)\n",
    "# for pedone in pedoni:\n",
    "#     pedone = cv2.resize(pedone, dsize=(128,64), interpolation=cv2.INTER_CUBIC)\n",
    "#     print(pedone.shape)\n",
    "\n",
    "\n",
    "for i in range(len(pedoni)):\n",
    "    # prima faccio blurring\n",
    "    pedoni[i] = cv2.GaussianBlur()\n",
    "    pedoni[i] = cv2.resize(pedoni[i], dsize=(64, 128), interpolation=cv2.INTER_CUBIC)\n",
    "    print(pedoni[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedone1, pedone2, pedone3, pedone4 = pedoni\n",
    "\n",
    "cv2.imshow('Pedone1', pedone1)\n",
    "cv2.imshow('Pedone2', pedone2)\n",
    "cv2.imshow('Pedone3', pedone3)\n",
    "cv2.imshow('Pedone4', pedone4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 80, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pedoni[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedone1, pedone2, pedone3, pedone4 = pedoni\n",
    "\n",
    "cv2.imshow('Pedone1', pedone1)\n",
    "cv2.imshow('Pedone2', pedone2)\n",
    "cv2.imshow('Pedone3', pedone3)\n",
    "cv2.imshow('Pedone4', pedone4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56700,)\n",
      "(343980,)\n",
      "(612360,)\n",
      "(453600,)\n"
     ]
    }
   ],
   "source": [
    "# se volessi applicare un descrittore locale per ogni sottoimmagine\n",
    "# h_pedone1 = hog.compute(pedone1)\n",
    "# h_pedone1\n",
    "h_pedoni = []\n",
    "for pedone in pedoni:\n",
    "    h = hog.compute(pedone)\n",
    "    print(h.shape)\n",
    "    h_pedoni.append(h)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/28390614/opencv-hogdescripter-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"test.jpg\",0)\n",
    "winSize = (64,128)\n",
    "# blockSize = (16,16)\n",
    "# blockStride = (8,8)\n",
    "# cellSize = (8,8)\n",
    "# nbins = 9\n",
    "# derivAperture = 1\n",
    "# winSigma = 4.\n",
    "# histogramNormType = 0\n",
    "# L2HysThreshold = 2.0000000000000001e-01\n",
    "# gammaCorrection = 0\n",
    "# nlevels = 64\n",
    "hog = cv2.HOGDescriptor(winSize)\n",
    "#compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
    "winStride = (8,8)\n",
    "padding = (8,8)\n",
    "locations = ((10,20),)\n",
    "hist = hog.compute(image,winStride,padding,locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a snippet of code to initialize an cv2.HOGDescriptor with different parameters (The terms I used here are standard terms which are well defined in OpenCV documentation here)\n",
    "\n",
    "Here: https://docs.opencv.org/2.4/modules/gpu/doc/object_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant hog descriptor will have dimension as: 9 orientations X (4 corner blocks that get 1 normalization + 6x4 blocks on the edges that get 2 normalizations + 6x6 blocks that get 4 normalizations) = 1764. as I have given only one location for hog.compute()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on HOGDescriptor in module cv2 object:\n",
      "\n",
      "class HOGDescriptor(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  checkDetectorSize(...)\n",
      " |      checkDetectorSize() -> retval\n",
      " |      .   @brief Checks if detector size equal to descriptor size.\n",
      " |  \n",
      " |  compute(...)\n",
      " |      compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
      " |      .   @brief Computes HOG descriptors of given image.\n",
      " |      .       @param img Matrix of the type CV_8U containing an image where HOG features will be calculated.\n",
      " |      .       @param descriptors Matrix of the type CV_32F\n",
      " |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .       @param padding Padding\n",
      " |      .       @param locations Vector of Point\n",
      " |  \n",
      " |  computeGradient(...)\n",
      " |      computeGradient(img, grad, angleOfs[, paddingTL[, paddingBR]]) -> grad, angleOfs\n",
      " |      .   @brief  Computes gradients and quantized gradient orientations.\n",
      " |      .       @param img Matrix contains the image to be computed\n",
      " |      .       @param grad Matrix of type CV_32FC2 contains computed gradients\n",
      " |      .       @param angleOfs Matrix of type CV_8UC2 contains quantized gradient orientations\n",
      " |      .       @param paddingTL Padding from top-left\n",
      " |      .       @param paddingBR Padding from bottom-right\n",
      " |  \n",
      " |  detect(...)\n",
      " |      detect(img[, hitThreshold[, winStride[, padding[, searchLocations]]]]) -> foundLocations, weights\n",
      " |      .   @brief Performs object detection without a multi-scale window.\n",
      " |      .       @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      " |      .       @param foundLocations Vector of point where each point contains left-top corner point of detected object boundaries.\n",
      " |      .       @param weights Vector that will contain confidence values for each detected object.\n",
      " |      .       @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      " |      .       Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      " |      .       But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      " |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .       @param padding Padding\n",
      " |      .       @param searchLocations Vector of Point includes set of requested locations to be evaluated.\n",
      " |  \n",
      " |  detectMultiScale(...)\n",
      " |      detectMultiScale(img[, hitThreshold[, winStride[, padding[, scale[, groupThreshold[, useMeanshiftGrouping]]]]]]) -> foundLocations, foundWeights\n",
      " |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      " |      .       of rectangles.\n",
      " |      .       @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      " |      .       @param foundLocations Vector of rectangles where each rectangle contains the detected object.\n",
      " |      .       @param foundWeights Vector that will contain confidence values for each detected object.\n",
      " |      .       @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      " |      .       Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      " |      .       But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      " |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .       @param padding Padding\n",
      " |      .       @param scale Coefficient of the detection window increase.\n",
      " |      .       @param groupThreshold Coefficient to regulate the similarity threshold. When detected, some objects can be covered\n",
      " |      .       by many rectangles. 0 means not to perform grouping.\n",
      " |      .       @param useMeanshiftGrouping indicates grouping algorithm\n",
      " |  \n",
      " |  getDescriptorSize(...)\n",
      " |      getDescriptorSize() -> retval\n",
      " |      .   @brief Returns the number of coefficients required for the classification.\n",
      " |  \n",
      " |  getWinSigma(...)\n",
      " |      getWinSigma() -> retval\n",
      " |      .   @brief Returns winSigma value\n",
      " |  \n",
      " |  load(...)\n",
      " |      load(filename[, objname]) -> retval\n",
      " |      .   @brief loads HOGDescriptor parameters and coefficients for the linear SVM classifier from a file\n",
      " |      .       @param filename Name of the file to read.\n",
      " |      .       @param objname The optional name of the node to read (if empty, the first top-level node will be used).\n",
      " |  \n",
      " |  save(...)\n",
      " |      save(filename[, objname]) -> None\n",
      " |      .   @brief saves HOGDescriptor parameters and coefficients for the linear SVM classifier to a file\n",
      " |      .       @param filename File name\n",
      " |      .       @param objname Object name\n",
      " |  \n",
      " |  setSVMDetector(...)\n",
      " |      setSVMDetector(svmdetector) -> None\n",
      " |      .   @brief Sets coefficients for the linear SVM classifier.\n",
      " |      .       @param svmdetector coefficients for the linear SVM classifier.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  getDaimlerPeopleDetector(...)\n",
      " |      getDaimlerPeopleDetector() -> retval\n",
      " |      .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      " |  \n",
      " |  getDefaultPeopleDetector(...)\n",
      " |      getDefaultPeopleDetector() -> retval\n",
      " |      .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  L2HysThreshold\n",
      " |      L2HysThreshold\n",
      " |  \n",
      " |  blockSize\n",
      " |      blockSize\n",
      " |  \n",
      " |  blockStride\n",
      " |      blockStride\n",
      " |  \n",
      " |  cellSize\n",
      " |      cellSize\n",
      " |  \n",
      " |  derivAperture\n",
      " |      derivAperture\n",
      " |  \n",
      " |  gammaCorrection\n",
      " |      gammaCorrection\n",
      " |  \n",
      " |  histogramNormType\n",
      " |      histogramNormType\n",
      " |  \n",
      " |  nbins\n",
      " |      nbins\n",
      " |  \n",
      " |  nlevels\n",
      " |      nlevels\n",
      " |  \n",
      " |  signedGradient\n",
      " |      signedGradient\n",
      " |  \n",
      " |  svmDetector\n",
      " |      svmDetector\n",
      " |  \n",
      " |  winSigma\n",
      " |      winSigma\n",
      " |  \n",
      " |  winSize\n",
      " |      winSize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "help(cv2.HOGDescriptor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Different way to initialize HOGDescriptor:\n",
    "One more way to initialize is from xml file which contains all parameter values:\n",
    "\n",
    "hog = cv2.HOGDescriptor(\"hog.xml\")\n",
    "\n",
    "To get an xml file one can do following:\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.save(\"hog.xml\")\n",
    "\n",
    "and edit the respective parameter values in xml file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
